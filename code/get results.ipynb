{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the results in the paper\n",
    "\n",
    "In this notebook,\n",
    "- we load the data and get summary statistics\n",
    "- we plot figure 1 in the paper, showing the distribution of our annotation\n",
    "- we plot figure 2 in the paper, showing the performance of different types of ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "official_finer_data = pd.read_csv(\"../data/sexism_data/sexism_annotations.csv\", index_col = False, encoding = 'utf-8')\n",
    "official_data = pd.read_csv(\"../data/sexism_data/sexism_data.csv\", index_col = False, encoding = 'utf-8')\n",
    "\n",
    "finer_data = pd.read_csv(\"../data/all_data_annotations.csv\", sep = \"\\t\", index_col = False, encoding = 'utf-8')\n",
    "data = pd.read_csv(\"../data/all_data_augmented.csv\", sep = \"\\t\", index_col = False, encoding = 'utf-8')\n",
    "\n",
    "official_finer_data['id'] = official_finer_data['id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sexist</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>benevolent</th>\n",
       "      <td>889.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>callme</th>\n",
       "      <td>1641.0</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hostile</th>\n",
       "      <td>967.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>7985.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scales</th>\n",
       "      <td>338.0</td>\n",
       "      <td>540.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sexist       False  True \n",
       "dataset                  \n",
       "benevolent   889.0  189.0\n",
       "callme      1641.0  790.0\n",
       "hostile      967.0  290.0\n",
       "other       7985.0    NaN\n",
       "scales       338.0  540.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_data.groupby(['dataset', 'sexist']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sexist</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>benevolent</th>\n",
       "      <td>891</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>callme</th>\n",
       "      <td>1641</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hostile</th>\n",
       "      <td>967</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>691</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scales</th>\n",
       "      <td>353</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sexist      False  True \n",
       "dataset                 \n",
       "benevolent    891    183\n",
       "callme       1641    773\n",
       "hostile       967    278\n",
       "other         691      8\n",
       "scales        353    536"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['dataset', 'sexist']).size().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "official_finer_data = official_finer_data.merge(official_data, on = ['id'])\n",
    "official_finer_orig = official_finer_data[official_finer_data['of_id'] == -1] # drop modifications\n",
    "official_finer_mod = official_finer_data[official_finer_data['of_id'] != -1] # only keep modifications\n",
    "\n",
    "official_mod = official_data[official_data['of_id'] != -1]\n",
    "official_orig = official_data[official_data['of_id'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "0.08047867       1\n",
       "0.11081803       1\n",
       "benevolent     404\n",
       "callme        1151\n",
       "hostile        579\n",
       "other           25\n",
       "scales         135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_mod.drop_duplicates('id').groupby('dataset').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "0.11081803      1\n",
       "benevolent    396\n",
       "callme        909\n",
       "hostile       570\n",
       "other          22\n",
       "scales        126\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_mod.drop_duplicates('text').groupby('dataset').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent     678\n",
       "callme        1280\n",
       "hostile        655\n",
       "other         7960\n",
       "scales         764\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig.drop_duplicates('text').groupby('dataset').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent    388\n",
       "callme        899\n",
       "hostile       558\n",
       "other          18\n",
       "scales        117\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.drop_duplicates('text').groupby('dataset').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent     676\n",
       "callme        1280\n",
       "hostile        678\n",
       "scales         743\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_finer_orig.drop_duplicates('id').groupby(['dataset']).size() # corresponds to '#mod' column in Table 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent     404\n",
       "callme        1151\n",
       "hostile        579\n",
       "scales         135\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_finer_mod.drop_duplicates('id').groupby(['dataset']).size() # corresponds to '#mod' column in Table 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finer_data = finer_data.merge(data, on = ['_id', 'dataset'])\n",
    "finer_orig = finer_data[finer_data['of_id'].isna()] # drop modifications\n",
    "finer_mod = finer_data[~finer_data['of_id'].isna()] # only keep modifications\n",
    "\n",
    "orig = data[data['of_id'].isna()] # drop modifications\n",
    "mod = data[~data['of_id'].isna()] # only keep modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent     678\n",
       "callme        1280\n",
       "hostile        678\n",
       "other          678\n",
       "scales         764\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finer_orig.drop_duplicates('_id').groupby(['dataset']).size() # corresponds to 'w/ annot.' column in Table 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset\n",
       "benevolent     396\n",
       "callme        1134\n",
       "hostile        567\n",
       "other           21\n",
       "scales         125\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finer_mod.drop_duplicates('_id').groupby(['dataset']).size() # corresponds to '#mod' column in Table 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "5    2269\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "official_finer_mod.groupby(['id']).size().reset_index(name='count').groupby('count').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "5    2222\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finer_mod = finer_mod[finer_mod['dataset'] != 'other']\n",
    "finer_mod.groupby(['_id']).size().reset_index(name='count').groupby('count').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_annotations(df):\n",
    "    df['content_categorical'] = df.content.apply(lambda x: 'content_%d'%x)\n",
    "    df['phrasing_categorical'] = df.phrasing.apply(lambda x: 'phrasing_%d'%x)\n",
    "\n",
    "    df['content_merged_12_56'] = df.content.map({1:1, 2:1, \n",
    "                                                 3:3, 4:4, \n",
    "                                                 5:5, 6:5})\n",
    "    df['content_merged_12_56_categorical'] = df.content_merged_12_56.apply(lambda x: 'content_%d'%x)\n",
    "\n",
    "\n",
    "    df['content_merged_phrasing_categorical'] = df.content_merged_12_56_categorical+df.phrasing_categorical\n",
    "\n",
    "    df['content_phrasing_categorical'] = df.content_categorical+df.phrasing_categorical\n",
    "\n",
    "    df['content_binary'] = df.content.apply(lambda x: x<=4)\n",
    "    df['phrasing_binary'] = df.phrasing.apply(lambda x: x==1)\n",
    "\n",
    "    df['sexist_binary'] = df.content_binary | df.phrasing_binary\n",
    "    df['sexist_factorial'] = df.content_binary.astype(str) + df.phrasing_binary.astype(str)\n",
    "    \n",
    "encode_annotations(finer_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "def maj_vote(x,majority_at_least=3):\n",
    "    most_common =  Counter(x).most_common(2)\n",
    "    if len(most_common)<2: #perfect agreement\n",
    "        return most_common[0][0]\n",
    "    else: #some disagreement\n",
    "        (k1, v1),(k2, v2) = most_common\n",
    "        if (v1<majority_at_least) or (v2==v1): return np.nan\n",
    "        else: return k1\n",
    "\n",
    "def get_majority_df(df):\n",
    "    df_majority = df.copy()\n",
    "\n",
    "    df_majority=df_majority[[u'id', 'dataset', 'text',\n",
    "           u'content_categorical', u'phrasing_categorical',\n",
    "           u'content_merged_12_56_categorical',\n",
    "           u'content_binary', u'phrasing_binary', u'sexist_binary', #'sexist_factorial', 'content_merged_phrasing_categorical'\n",
    "                            ]].groupby(['id', 'dataset']).agg(maj_vote).reset_index()\n",
    "    return df_majority\n",
    "\n",
    "df_majority = get_majority_df(finer_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_majority['dataset'] = df_majority.dataset.map({\"benevolent\":\"benevolent (b)\", 'hostile':'hostile (h)','other':'other (o)', 'callme':'callme (c)','scales':'scales (s)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_majority['plot_order'] = df_majority.dataset.apply(lambda x:{\"benevolent (b)\":0, 'hostile (h)':1,'other (o)':2, 'callme (c)':3,'scales (s)':4}[x])\n",
    "#df_majority['plot_order'] = df_majority.dataset.apply(lambda x:dict(enumerate((df_majority.content_categorical.unique())))[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sns.plotting_context('notebook', font_scale=1.15):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, False, True, figsize=(21, 3.))\n",
    "\n",
    "    df_majority['plot_order'] = df_majority.dataset.apply(lambda x:{\"benevolent (b)\":0, 'hostile (h)':1,'other (o)':2, 'callme (c)':3,'scales (s)':4}[x])\n",
    "    df_majority['plot_order'] += df_majority.content_categorical.apply(lambda x:dict((j, i) for i, j in enumerate((df_majority.content_categorical.unique())))[x])\n",
    "    by_content = df_majority.sort_values('plot_order', ).groupby(['dataset', 'content_categorical'], sort=False)['dataset'].count().unstack('content_categorical').fillna(0)\n",
    "\n",
    "    ax=by_content[sorted(by_content.columns)].plot(kind='bar', stacked=True,ax=ax1)\n",
    "    sns.despine()\n",
    "    # Put a legend below current axis\n",
    "    _=ax.legend(['sexist expectations', 'sexist stereotypes', \n",
    "                           'endorsement of inequality', 'rejection of inequality', \n",
    "                           'maybe sexist', 'not sexist'], loc='lower center', bbox_to_anchor=(.5, 1.), ncol=2,\n",
    "              fancybox=False, shadow=False, frameon=False, title='content')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('samples', )\n",
    "\n",
    "\n",
    "    df_majority['plot_order'] = df_majority.dataset.apply(lambda x:{\"benevolent (b)\":0, 'hostile (h)':10,'other (o)':20, 'callme (c)':30,'scales (s)':40}[x])\n",
    "    df_majority['plot_order'] += df_majority.phrasing_categorical.apply(lambda x:dict((j, i) for i, j in enumerate((df_majority.phrasing_categorical.unique())))[x])\n",
    "#     df_majority['plot_order'] += df_majority.phrasing_categorical.apply(lambda x:dict((j, i) for i, j in enumerate(sorted(df_majority.phrasing_categorical.unique())))[x])\n",
    "    \n",
    "    by_phrasing = df_majority.sort_values('plot_order', ).groupby(['dataset', 'phrasing_categorical'], sort=False)['dataset'].count().unstack('phrasing_categorical').fillna(0)\n",
    "\n",
    "    ax=by_phrasing[sorted(by_phrasing.columns)].plot(kind='bar', stacked=True,ax=ax2)\n",
    "    sns.despine()\n",
    "    # Put a legend below current axis\n",
    "    _=ax.legend(['uncivil and sexist', 'uncivil but not sexist', 'civil'],\n",
    "                loc='lower center', bbox_to_anchor=(.5, 1.), ncol=1,\n",
    "              fancybox=False, shadow=False, frameon=False, title=\"phrasing\")\n",
    "\n",
    "    \n",
    "    \n",
    "    by_sexism = df_majority.sort_values('plot_order', ).groupby(['dataset', 'sexist_binary'], sort=False)['dataset'].count().unstack('sexist_binary').fillna(0)\n",
    "    by_sexism.columns=['not sexist', 'sexist', ]\n",
    "    \n",
    "    ax=by_sexism[['sexist','not sexist']].plot(kind='bar', stacked=True,ax=ax3)\n",
    "    sns.despine()\n",
    "    # Put a legend below current axis\n",
    "    _=ax.legend(loc='lower center', bbox_to_anchor=(.5, 1.), ncol=1,\n",
    "              fancybox=False, shadow=False, frameon=False, title=\"sexism (content or phrasing)\")\n",
    "    _=ax.set_xlabel('')\n",
    "    plt.autoscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../results/all_runs_new_data.pkl2\", 'rb') as f:\n",
    "    results_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toplot=results_df.copy()\n",
    "\n",
    "toplot = toplot.melt(id_vars=['train', 'test', 'train_domain'], value_vars = [u'macro avg f1-score',\n",
    "u'sexist recall',\n",
    "         u'sexist precision',])\n",
    "toplot = toplot[toplot.train.isin(['original_logit', 'adversarial_logit', \n",
    "                                   'original_bert', 'adversarial_bert',\n",
    "                                   u'adversarial_bert_finetuned',u'original_bert_finetuned',\n",
    "                                   'original_cnn', 'adversarial_cnn',\n",
    "                                   'original_thold','original_baseline', ])]\n",
    "\n",
    "toplot = toplot[toplot.test.isin([\n",
    "    'goldtrain_original',\n",
    "    'omnibus_original', 'omnibus_adversarial', \n",
    "    'replication_original','replication_adversarial', \n",
    "    'reproduction_original','reproduction_adversarial'])]\n",
    "\n",
    "toplot = toplot[toplot.train_domain.isin(['goldtrain', 'omnibus', 'replication', 'reproduction'])]\n",
    "\n",
    "\n",
    "toplot['test'] =toplot.test.map(dict(zip(['reproduction_original', 'reproduction_adversarial', \n",
    "                             'replication_original', 'replication_adversarial', \n",
    "                             'goldtrain_original',\n",
    "                            'omnibus_original', 'omnibus_adversarial', ],\n",
    "                        ['bho', 'bho-M', \n",
    "                             'c', 'c-M', \n",
    "                             's',\n",
    "                            'bhocs', 'bhocs-M', ])))\n",
    "\n",
    "toplot['train'] = toplot.train.map(dict(zip(['original_logit', 'adversarial_logit', \n",
    "                                   'original_bert', 'adversarial_bert',\n",
    "                                   u'adversarial_bert_finetuned',u'original_bert_finetuned',\n",
    "                                   'original_cnn', 'adversarial_cnn',\n",
    "                                   'original_thold','original_baseline', ], \n",
    "                                    ['logit', 'logit-M', \n",
    "                                   'bert', 'bert-M',\n",
    "                                   u'bert finetuned-M',u'bert finetuned',\n",
    "                                   'cnn', 'cnn-M',\n",
    "                                   'toxicity','gender word', ])))\n",
    "\n",
    "toplot['train_domain'] = toplot.train_domain.map(dict(zip([u'goldtrain', u'omnibus', u'replication', u'reproduction'], \n",
    "                                    [u's (scales)', u'bhocs (omnibus)', u'c (callme)', u'bho (Jha17)'])))\n",
    "\n",
    "toplot = toplot[(toplot.train_domain!= 's (scales)') & (~toplot.train.isin(['bert', 'bert-M']))]\n",
    "\n",
    "toplot.columns = [u'model', u'test', u'train_domain', u'variable', u'value']\n",
    "\n",
    "toplot = toplot[toplot.variable == u'macro avg f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toplot['train_domain'] = toplot['train_domain'].apply(lambda x: x.split(' ')[0])\n",
    "toplot['train_domain']  += toplot.model.str.endswith('-M').apply(lambda x: x and '-M' or '')\n",
    "\n",
    "toplot['model'] = toplot.model.apply(lambda x: x.endswith('-M') and x[:-2] or x)\n",
    "\n",
    "gender_bline = toplot[toplot['model'] == 'gender word'].value.mean()\n",
    "toxicity_bline = toplot[toplot['model'] == 'toxicity'].value.mean()\n",
    "\n",
    "\n",
    "\n",
    "toplot = toplot[~toplot.model.isin(['toxicity', 'gender word',])]\n",
    "\n",
    "toplot['train_domain'] = toplot.train_domain.map(dict(zip([u'bhocs', u'bhocs-M', u'c', u'c-M', u'bho', u'bho-M'],\n",
    "                                [u'bhocs', u'bhocs-M', u'c', u'c-M', u'bho', u'bho-M'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "custom_palette = sns.color_palette(\"Paired\",8)\n",
    "sns.palplot(custom_palette)\n",
    "\n",
    "custom_palette[-1] = (.5, .5, .5)\n",
    "custom_palette[-2] = (.6, .6, .6)\n",
    "\n",
    "sns.palplot(custom_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_order = ['bho', 'bho-M', \n",
    " 'c', 'c-M', \n",
    " 'bhocs', 'bhocs-M', ]\n",
    "model_order = ['logit', 'cnn', u'bert finetuned',]\n",
    "marker_order = ['.','o', \"d\",\"D\",  \"<\",\">\",]\n",
    "with plt.rc_context(dict(sns.axes_style(\"whitegrid\"),\n",
    "                         **sns.plotting_context(\"notebook\", font_scale=1.35, \n",
    "                                                rc={\"lines.linewidth\": 1.,}\n",
    "                                               ))):\n",
    "    g = sns.catplot(x='test', y='value', col='model', hue='train_domain',  \n",
    "                    data=toplot, kind='point',\n",
    "                    sharex=True, sharey=True,\n",
    "                    col_order = model_order,\n",
    "                    hue_order = data_order,\n",
    "                    order = data_order+['s'],\n",
    "                    markers=marker_order,\n",
    "                    legend=False,\n",
    "                    legend_out=True,\n",
    "                \n",
    "                    palette=custom_palette,\n",
    "                    dodge=.5,\n",
    "                    join=False,\n",
    "                    aspect=1.3\n",
    "                   )\n",
    "    g.set_xlabels(\"test set\")\n",
    "    for ax in g.axes[0]: \n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, ha='center')\n",
    "        plt.setp(ax.collections, sizes=[40])\n",
    "\n",
    "    g.axes[0, 0].set_ylabel(u'macro avg f1-score')\n",
    "\n",
    "    g.fig.suptitle('performance by model type', x=0, ha='left', y=1.1)\n",
    "    l=g.axes[0, 2].legend(loc='upper right', bbox_to_anchor=(0.3, 1.4), ncol=3,\n",
    "              fancybox=False, shadow=False, frameon=False)\n",
    "    l.set_title('training set:')\n",
    "    l.get_title().set_position((-240, -22))\n",
    "    plt.setp(l.get_title(),fontsize=l.prop.get_size())\n",
    "\n",
    "    clrs = dict(zip(data_order,\n",
    "                   custom_palette, ))\n",
    "    mrkrs = dict(zip(data_order,marker_order ))    \n",
    "    pltn = {j: i for i, j in enumerate(model_order)}\n",
    "    mdln = {j:i for i, j in enumerate(data_order)}\n",
    "    import matplotlib.patches as patches\n",
    "    for a, d in toplot.groupby([\"train_domain\",\"model\"]).mean().reset_index().groupby(\"model\"):\n",
    "        for mdl, v in d.set_index('train_domain').value.to_dict().items():\n",
    "            g.axes[0, pltn[a]].scatter([6.8+(mdln[mdl]/8.)], [d.set_index('train_domain').value.to_dict()[mdl]],\n",
    "                                          c=clrs[mdl], marker=mrkrs[mdl], clip_on=True)\n",
    "    for i in range(3):\n",
    "        l1 = g.axes[0, i].plot((6.7, 7.75), \n",
    "                                    (gender_bline, gender_bline),\n",
    "                                    ls=':', lw=2, c='.3', clip_on = True, #dashes=(1, 1+mdln[mdl]/3.)\n",
    "                                      )  \n",
    "\n",
    "        l2 = g.axes[0, i].plot((6.7, 7.75), \n",
    "                                    (toxicity_bline, toxicity_bline),\n",
    "                                    ls='--', lw=2, c='.3', clip_on = True, #dashes=(1, 1+mdln[mdl]/3.)\n",
    "                                      )  \n",
    "\n",
    "    for i in range(3):\n",
    "        g.axes[0, i].add_patch( patches.Rectangle((6.7,g.axes[0, pltn[a]].get_ylim()[0]),\n",
    "                                                        1.05,.9-g.axes[0, pltn[a]].get_ylim()[0],\n",
    "                                                        linewidth=2,\n",
    "                                                        edgecolor='.7',\n",
    "                                                        facecolor='none',\n",
    "                                                        clip_on=False))\n",
    "        g.axes[0, i].text(6.7+1.05/2, .92, 'avg', ha='center')\n",
    "        \n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    lss = [':', '--']\n",
    "    lines = [Line2D([0], [0], color='.3', linewidth=2, linestyle=ll) for ll in lss]\n",
    "    labels = ['gender word', 'toxicity',]\n",
    "    ll=g.axes[0, i].legend(lines, labels, loc='upper right', bbox_to_anchor=(1., 1.4), ncol=1,\n",
    "              fancybox=False, shadow=False, frameon=False)\n",
    "    ll.set_title('baseline:')\n",
    "    ll.get_title().set_position((-140, -22))\n",
    "    plt.setp(l.get_title(),fontsize=l.prop.get_size())\n",
    "    g.axes[0, i].add_artist(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icwsm20",
   "language": "python",
   "name": "icwsm20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
